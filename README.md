# Swiggy Review Scrapping
# ğŸ§  Google Play Store Review Trend Analysis

An automated, agentic AI pipeline that fetches Google Play Store reviews, normalizes text, classifies them into humanâ€‘explainable topics, and generates a **30â€‘day trend analysis report table** showing how issues evolve over time.

---

## Live Demo
(Not applicable â€” this is a Jupyter Notebook project. See sample outputs in `/output/`.)

---

## Tech Stack
- Python 3.10+
- Jupyter Notebook
- pandas (dataframes, aggregation, pivot)
- google-play-scraper (fetch reviews)
- sentence-transformers (semantic embeddings)
- rapidfuzz (fuzzy text matching)
- seaborn / matplotlib (optional visualization)

---

## âš™ï¸ Setup Instructions

** 1. Clone the repository**

Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Run the notebook
jupyter notebook assignment.ipynb

4ï¸âƒ£ Provide inputs
- App store link (e.g. https://play.google.com/store/apps/details?id=in.swiggy.android)
- Target date (e.g. 2025-12-20)
  
5ï¸âƒ£ Generate outputs
- Normalized + classified reviews
- Daily topic counts (trend)
- Final 30â€‘day trend analysis table (last_30)
- Exported CSVs in /output/

âœ¨ Key Features Implemented
ğŸ“ Automated Pipeline
- Fetches reviews directly from Google Play Store
- Cleans text with normalization function
- Classifies reviews into topics using fuzzy + semantic matching
  
ğŸ“Š Trend Analysis
- Groups reviews by date and topic
- Builds a 30â€‘day pivot table for trend reporting
  
ğŸ¨ Humanâ€‘Explainable Classifier
- Topics defined with seed phrases (e.g. â€œDelivery issueâ€, â€œFood staleâ€)
- Transparent logic: fuzzy match â†’ semantic similarity â†’ fallback
  
ğŸ“‚ Sample Outputs
- Daily counts (trend_sample.csv)
- 30â€‘day trend table (trend_table_30days.csv)

ğŸ§© Assumptions Made
- Reviews are fetched fresh at runtime (no cached dataset).
- Topics are predefined and limited to assignment scope.
- Analysis is focused on last 30 days only.
- No authentication or external API beyond google-play-scraper.

â± Time Spent on the Assignment
- Setup & environment: 1 hour
- Data fetching & cleaning: 1.5 hours
- Classifier design & testing: 2 hours
- Trend aggregation & pivot: 1 hour
- Documentation & outputs: 1 hour
Total: ~6.5 hours

ğŸ“‚Video Link:- https://drive.google.com/file/d/1V7F1wqJMfOG-cPfvIqvPpNkIkEhQq0aw/view?usp=sharing

```bash
git clone <your-repo-link>
cd swiggy-review-trends
